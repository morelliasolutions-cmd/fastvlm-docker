# FastVLM 1.5B Docker Deployment

D√©ploiement de FastVLM 1.5B avec une API HTTP pour Easypanel et n8n.

## üöÄ Fonctionnalit√©s

- API REST avec FastAPI
- Accepte des images encod√©es en base64
- **Optimis√© pour CPU uniquement** (parfait pour VPS sans GPU)
- Documentation automatique de l'API (Swagger UI)
- Health check endpoint

## üìã Pr√©requis

- Docker et Docker Compose install√©s
- **Au moins 4-6GB de RAM disponible** (CPU uniquement)
- Espace disque: ~5GB pour le mod√®le et d√©pendances
- **CPU avec au moins 2 cores recommand√©s**

## üê≥ D√©ploiement sur Easypanel

### Option 1: Via Docker Compose (Recommand√©)

1. Dans Easypanel, sur la page Source du service:
   - S√©lectionnez "docker-compose.yml"
   - Copiez le contenu de `docker-compose.yml` dans le champ pr√©vu
   - OU cliquez sur "Git" et entrez:
     - **URL du r√©pertoire**: URL de votre d√©p√¥t Git (si vous poussez ce code sur Git)
     - **Branche**: `main` ou `master`
     - **Chemin de construction**: `/`
     - **Fichier Docker Compose**: `docker-compose.yml`

2. Cliquez sur "Enregistrer" puis "D√©ployer"

### Option 2: Via Git Repository

1. Cr√©ez un d√©p√¥t Git avec ce code
2. Dans Easypanel, s√©lectionnez "Git"
3. Configurez:
   - **URL du r√©pertoire**: `https://github.com/votre-username/fastvlm-docker.git`
   - **Branche**: `main`
   - **Chemin de construction**: `/`
   - **Fichier Docker Compose**: `docker-compose.yml`
4. Si le d√©p√¥t est priv√©, g√©n√©rez une cl√© SSH dans Easypanel et ajoutez-la √† votre d√©p√¥t Git

## üîå API Endpoints

### Health Check
```http
GET /health
```

### G√©n√©rer une r√©ponse
```http
POST /generate
Content-Type: application/json

{
  "image": "data:image/png;base64,iVBORw0KGgoAAAANS...",
  "prompt": "What is in this image? Describe it in detail.",
  "max_length": 512
}
```

### Chat (alias pour /generate)
```http
POST /chat
Content-Type: application/json

{
  "image": "base64_encoded_image_string",
  "prompt": "What do you see?",
  "max_length": 256
}
```

### Documentation interactive
```
GET /docs
```

## üìù Utilisation avec n8n

### 1. Configuration HTTP Request

Dans n8n, cr√©ez un workflow avec:

1. **N≈ìud "Read Binary File"** ou **"HTTP Request"** (pour r√©cup√©rer l'image)
2. **N≈ìud "Function"** pour convertir en base64:
   ```javascript
   const binaryData = $input.item.binary.data;
   const base64 = binaryData.toString('base64');
   const dataUri = `data:image/png;base64,${base64}`;
   
   return {
     json: {
       image: dataUri,
       prompt: "What is in this image? Describe it in detail.",
       max_length: 512
     }
   };
   ```

3. **N≈ìud "HTTP Request"** pour appeler FastVLM:
   - **Method**: POST
   - **URL**: `http://fastvlm:8000/generate` (ou l'URL externe si n8n est sur un autre serveur)
   - **Authentication**: None (ou ajoutez une authentification si n√©cessaire)
   - **Body Content Type**: JSON
   - **Body**: Utilisez la sortie du n≈ìud Function

4. **N≈ìud "Set"** pour traiter la r√©ponse:
   ```javascript
   return {
     json: {
       description: $json.response
     }
   };
   ```

### 2. Exemple de requ√™te compl√®te

```json
{
  "image": "data:image/png;base64,iVBORw0KGgoAAAANS...",
  "prompt": "Analyze this image and describe what you see. Be specific and detailed.",
  "max_length": 512
}
```

### R√©ponse attendue:
```json
{
  "response": "I can see a beautiful landscape with mountains...",
  "model": "FastVLM-1.5B"
}
```

## üîß Configuration

### Variables d'environnement

- `MODEL_NAME`: Nom du mod√®le HuggingFace (d√©faut: `apple/FastVLM-1.5B`)
- `PORT`: Port du serveur (d√©faut: `8000`)
- `TORCH_DEVICE`: Device PyTorch (d√©faut: `cpu` - optimis√© pour CPU uniquement)

### Configuration CPU uniquement

Cette configuration est **optimis√©e pour CPU uniquement** par d√©faut. Le `docker-compose.yml` utilise `Dockerfile.cpu` qui installe PyTorch CPU (plus l√©ger, ~500MB au lieu de ~2GB).

**Performance CPU:**
- Chargement du mod√®le: ~30-60 secondes
- G√©n√©ration de r√©ponse: ~5-15 secondes selon la longueur
- M√©moire utilis√©e: ~4-5GB en fonctionnement

Pour am√©liorer les performances sur CPU:
- Augmentez `cpus` dans `docker-compose.yml`
- R√©duisez `max_length` dans vos requ√™tes (256 au lieu de 512)

## üêõ D√©pannage

### Le mod√®le ne charge pas
- V√©rifiez les logs: `docker logs fastvlm-1.5b`
- V√©rifiez l'espace disque (le mod√®le fait ~3GB)
- V√©rifiez la m√©moire disponible (au moins 4GB recommand√©)

### Erreur "Out of Memory" (CPU)
- R√©duisez `max_length` dans vos requ√™tes (essayez 256 au lieu de 512)
- R√©duisez les limites de m√©moire dans `docker-compose.yml` (minimum 4GB requis)
- Assurez-vous qu'aucun autre processus lourd ne tourne sur le VPS

### L'API ne r√©pond pas
- V√©rifiez que le port 8000 est expos√©
- V√©rifiez le health check: `curl http://localhost:8000/health`
- Consultez les logs du conteneur

## üìö Documentation

- **Guide de performance CPU** : Voir `CPU_PERFORMANCE.md` pour optimiser les performances sur CPU
- [FastVLM sur HuggingFace](https://huggingface.co/apple/FastVLM-1.5B)
- [Documentation FastAPI](https://fastapi.tiangolo.com/)
- [Documentation n8n](https://docs.n8n.io/)

## üìÑ Licence

Ce projet est fourni tel quel pour faciliter le d√©ploiement de FastVLM. Le mod√®le FastVLM est d√©velopp√© par Apple.
